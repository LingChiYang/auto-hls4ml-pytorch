{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "var = qmodel.layers[2].norm1.var_input_qtzr(torch.tensor(7652.373086, dtype=torch.float64))\n",
    "print(var_input_qtzr.int_bitwidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from quantizers import *\n",
    "import torch\n",
    "src = torch.load('./input_batch-1.pth')\n",
    "src_mask = torch.load('./src_mask.pth')\n",
    "print(src)\n",
    "qmodel = torch.load('./qmodel.pth')\n",
    "print(src.shape)\n",
    "src = src.type(torch.float64).to(torch.device('cpu'))\n",
    "qmodel = qmodel.to(torch.device('cpu'))\n",
    "qmodel.eval()\n",
    "with torch.no_grad():\n",
    "    output = qmodel(src, mask=src_mask)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDT4HLS(\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=182, out_features=182, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=182, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.3946451938505568, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=182, bias=True)\n",
      "        (norm1): LayerNorm((182,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((182,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.3946451938505568, inplace=False)\n",
      "        (dropout2): Dropout(p=0.3946451938505568, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((182,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "class NDT4HLS(torch.nn.Module):\n",
    "    def __init__(self, config, trial_length, num_neurons, device, max_spikes):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.trial_length = trial_length\n",
    "        self.num_neurons = num_neurons\n",
    "        self.device = device\n",
    "\n",
    "        # TODO buffer\n",
    "        if config.FULL_CONTEXT:\n",
    "            self.src_mask = None\n",
    "        else:\n",
    "            self.src_mask = {} # multi-GPU masks\n",
    "        if config.EMBED_DIM == 0:\n",
    "            self.num_input = num_neurons\n",
    "        else:\n",
    "            self.num_input = config.EMBED_DIM * num_neurons\n",
    "\n",
    "        self._init_transformer()\n",
    "        self.src_mask = self._get_or_generate_context_mask(torch.zeros(self.trial_length, self.trial_length, device=device))\n",
    "        self.padding_mask = torch.randint(0, 2, (self.trial_length, self.trial_length), device=device).bool()\n",
    "        #self.init_weights()\n",
    "\n",
    "    def _init_transformer(self):\n",
    "        norm = nn.LayerNorm(self.num_input)\n",
    "        #encoder_layer = nn.TransformerEncoderLayer(d_model=self.num_input, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=self.num_input, \n",
    "                                       nhead=self.config.NUM_HEADS,\n",
    "                                       dim_feedforward=self.config.HIDDEN_SIZE,\n",
    "                                       dropout=self.config.DROPOUT,\n",
    "                                       activation=self.config.ACTIVATION,\n",
    "                                       norm_first=self.config.PRE_NORM,\n",
    "                                       device=self.device),\n",
    "            self.config.NUM_LAYERS,\n",
    "            norm=norm\n",
    "        )\n",
    "    \n",
    "    def _get_or_generate_context_mask(self, src, do_convert=True, expose_ic=True):\n",
    "        if self.config.FULL_CONTEXT:\n",
    "            return None\n",
    "        if str(src.device) in self.src_mask:\n",
    "            return self.src_mask[str(src.device)]\n",
    "        size = src.size(0) # T\n",
    "        context_forward = self.config.CONTEXT_FORWARD\n",
    "        if self.config.CONTEXT_FORWARD < 0:\n",
    "            context_forward = size\n",
    "        mask = (torch.triu(torch.ones(size, size, device=src.device), diagonal=-context_forward) == 1).transpose(0, 1)\n",
    "        if self.config.CONTEXT_BACKWARD > 0:\n",
    "            back_mask = (torch.triu(torch.ones(size, size, device=src.device), diagonal=-self.config.CONTEXT_BACKWARD) == 1)\n",
    "            mask = mask & back_mask\n",
    "        if expose_ic and self.config.CONTEXT_WRAP_INITIAL and self.config.CONTEXT_BACKWARD > 0:\n",
    "            # Expose initial segment for IC\n",
    "            initial_mask = torch.triu(torch.ones(self.config.CONTEXT_BACKWARD, self.config.CONTEXT_BACKWARD, device=src.device))\n",
    "            mask[:self.config.CONTEXT_BACKWARD, :self.config.CONTEXT_BACKWARD] |= initial_mask\n",
    "        mask = mask.float()\n",
    "        def binary_mask_to_attn_mask(x):\n",
    "            return x.float().masked_fill(x == 0, float('-inf')).masked_fill(x == 1, float(0.0))\n",
    "        if do_convert:\n",
    "            mask = binary_mask_to_attn_mask(mask)\n",
    "        self.src_mask[str(src.device)] = mask\n",
    "        return self.src_mask[str(src.device)]\n",
    "\n",
    "    def forward(self, src):  \n",
    "        #src_mask = self._get_or_generate_context_mask(src)\n",
    "        output = self.transformer_encoder(src, mask=self.src_mask)\n",
    "        return output\n",
    "model4hls = torch.load('./model4hls.pth', map_location=torch.device('cpu'))\n",
    "print(model4hls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 07:50:01.437446: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-30 07:50:01.521623: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-30 07:50:01.835680: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-30 07:50:01.835728: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-30 07:50:01.835731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_config dict_keys(['state_dict', 'optim_state', 'lr_scheduler', 'config', 'best_val', 'best_unmasked_val', 'best_r2', 'max_spikes', 'num_neurons', 'trial_length', 'extra_state'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingchiyang/anaconda3/envs/auto-hls4ml/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from src.model import NeuralDataTransformer\n",
    "model_config = torch.load('./2a5324c4.lve.pth', map_location=torch.device('cpu'))\n",
    "print('model_config', model_config.keys())\n",
    "model = NeuralDataTransformer(model_config['config'][\"MODEL\"], 180, 182, torch.device('cpu'), 7)\n",
    "model.load_state_dict(model_config['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'ffn': {'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                         'input': {'bitwidth': 18,\n",
      "                                   'int_bitwidth': 8,\n",
      "                                   'quantize': False},\n",
      "                         'output': {'bitwidth': 18,\n",
      "                                    'int_bitwidth': 8,\n",
      "                                    'quantize': False},\n",
      "                         'weight': {'bitwidth': 18, 'int_bitwidth': 8}},\n",
      "             'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                          'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                          'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                          'weight': {'bitwidth': 18, 'int_bitwidth': 8}}},\n",
      "     'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "     'norm1': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'var_input': {'bitwidth': 12,\n",
      "                             'int_bitwidth': 3,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': 8,\n",
      "                              'signed': False}},\n",
      "     'norm2': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'var_input': {'bitwidth': 12,\n",
      "                             'int_bitwidth': 3,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': 8,\n",
      "                              'signed': False}},\n",
      "     'self_attn': {'exp_input': {'bitwidth': 12, 'int_bitwidth': 4},\n",
      "                   'exp_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': 8,\n",
      "                                  'signed': False},\n",
      "                   'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                               'input': {'bitwidth': 18,\n",
      "                                         'int_bitwidth': 8,\n",
      "                                         'quantize': False},\n",
      "                               'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                               'weight': {'bitwidth': 18, 'int_bitwidth': 8}},\n",
      "                   'inv_input': {'bitwidth': 12,\n",
      "                                 'int_bitwidth': 8,\n",
      "                                 'signed': False},\n",
      "                   'inv_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': 0,\n",
      "                                  'signed': False},\n",
      "                   'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                                'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                                'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                                'weight': {'bitwidth': 18, 'int_bitwidth': 8}},\n",
      "                   'row_sum': {'bitwidth': 18,\n",
      "                               'int_bitwidth': 8,\n",
      "                               'signed': False},\n",
      "                   'scale': {'bitwidth': 18, 'int_bitwidth': 0}}},\n",
      " 1: {'ffn': {'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                         'input': {'bitwidth': 18,\n",
      "                                   'int_bitwidth': 8,\n",
      "                                   'quantize': False},\n",
      "                         'output': {'bitwidth': 18,\n",
      "                                    'int_bitwidth': 8,\n",
      "                                    'quantize': False},\n",
      "                         'weight': {'bitwidth': 18, 'int_bitwidth': 8}},\n",
      "             'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                          'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                          'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                          'weight': {'bitwidth': 18, 'int_bitwidth': 8}}},\n",
      "     'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "     'norm1': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'var_input': {'bitwidth': 12,\n",
      "                             'int_bitwidth': 3,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': 8,\n",
      "                              'signed': False}},\n",
      "     'norm2': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'var_input': {'bitwidth': 12,\n",
      "                             'int_bitwidth': 3,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': 8,\n",
      "                              'signed': False}},\n",
      "     'self_attn': {'exp_input': {'bitwidth': 12, 'int_bitwidth': 4},\n",
      "                   'exp_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': 8,\n",
      "                                  'signed': False},\n",
      "                   'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                               'input': {'bitwidth': 18,\n",
      "                                         'int_bitwidth': 8,\n",
      "                                         'quantize': False},\n",
      "                               'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                               'weight': {'bitwidth': 18, 'int_bitwidth': 8}},\n",
      "                   'inv_input': {'bitwidth': 12,\n",
      "                                 'int_bitwidth': 8,\n",
      "                                 'signed': False},\n",
      "                   'inv_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': 0,\n",
      "                                  'signed': False},\n",
      "                   'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                                'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                                'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                                'weight': {'bitwidth': 18, 'int_bitwidth': 8}},\n",
      "                   'row_sum': {'bitwidth': 18,\n",
      "                               'int_bitwidth': 8,\n",
      "                               'signed': False},\n",
      "                   'scale': {'bitwidth': 18, 'int_bitwidth': 0}}},\n",
      " 2: {'ffn': {'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                         'input': {'bitwidth': 18,\n",
      "                                   'int_bitwidth': 8,\n",
      "                                   'quantize': False},\n",
      "                         'output': {'bitwidth': 18,\n",
      "                                    'int_bitwidth': 8,\n",
      "                                    'quantize': False},\n",
      "                         'weight': {'bitwidth': 18, 'int_bitwidth': 8}},\n",
      "             'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                          'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                          'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                          'weight': {'bitwidth': 18, 'int_bitwidth': 8}}},\n",
      "     'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "     'norm1': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'var_input': {'bitwidth': 12,\n",
      "                             'int_bitwidth': 3,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': 8,\n",
      "                              'signed': False}},\n",
      "     'norm2': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'var_input': {'bitwidth': 12,\n",
      "                             'int_bitwidth': 3,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': 8,\n",
      "                              'signed': False}},\n",
      "     'self_attn': {'exp_input': {'bitwidth': 12, 'int_bitwidth': 4},\n",
      "                   'exp_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': 8,\n",
      "                                  'signed': False},\n",
      "                   'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                               'input': {'bitwidth': 18,\n",
      "                                         'int_bitwidth': 8,\n",
      "                                         'quantize': False},\n",
      "                               'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                               'weight': {'bitwidth': 18, 'int_bitwidth': 8}},\n",
      "                   'inv_input': {'bitwidth': 12,\n",
      "                                 'int_bitwidth': 8,\n",
      "                                 'signed': False},\n",
      "                   'inv_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': 0,\n",
      "                                  'signed': False},\n",
      "                   'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                                'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                                'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                                'weight': {'bitwidth': 18, 'int_bitwidth': 8}},\n",
      "                   'row_sum': {'bitwidth': 18,\n",
      "                               'int_bitwidth': 8,\n",
      "                               'signed': False},\n",
      "                   'scale': {'bitwidth': 18, 'int_bitwidth': 0}}},\n",
      " 3: {'ffn': {'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                         'input': {'bitwidth': 18,\n",
      "                                   'int_bitwidth': 8,\n",
      "                                   'quantize': False},\n",
      "                         'output': {'bitwidth': 18,\n",
      "                                    'int_bitwidth': 8,\n",
      "                                    'quantize': False},\n",
      "                         'weight': {'bitwidth': 18, 'int_bitwidth': 8}},\n",
      "             'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                          'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                          'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                          'weight': {'bitwidth': 18, 'int_bitwidth': 8}}},\n",
      "     'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "     'norm1': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'var_input': {'bitwidth': 12,\n",
      "                             'int_bitwidth': 3,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': 8,\n",
      "                              'signed': False}},\n",
      "     'norm2': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "               'var_input': {'bitwidth': 12,\n",
      "                             'int_bitwidth': 3,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': 8,\n",
      "                              'signed': False}},\n",
      "     'self_attn': {'exp_input': {'bitwidth': 12, 'int_bitwidth': 4},\n",
      "                   'exp_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': 8,\n",
      "                                  'signed': False},\n",
      "                   'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                               'input': {'bitwidth': 18,\n",
      "                                         'int_bitwidth': 8,\n",
      "                                         'quantize': False},\n",
      "                               'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                               'weight': {'bitwidth': 18, 'int_bitwidth': 8}},\n",
      "                   'inv_input': {'bitwidth': 12,\n",
      "                                 'int_bitwidth': 8,\n",
      "                                 'signed': False},\n",
      "                   'inv_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': 0,\n",
      "                                  'signed': False},\n",
      "                   'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                                'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                                'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "                                'weight': {'bitwidth': 18, 'int_bitwidth': 8}},\n",
      "                   'row_sum': {'bitwidth': 18,\n",
      "                               'int_bitwidth': 8,\n",
      "                               'signed': False},\n",
      "                   'scale': {'bitwidth': 18, 'int_bitwidth': 0}}},\n",
      " 'norm': {'bias': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "          'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "          'mean': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "          'output': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "          'scale': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "          'var_input': {'bitwidth': 12, 'int_bitwidth': 3, 'signed': False},\n",
      "          'var_output': {'bitwidth': 18, 'int_bitwidth': 8, 'signed': False}}}\n"
     ]
    }
   ],
   "source": [
    "from quantizers import *\n",
    "import json\n",
    "import copy\n",
    "from pprint import pprint\n",
    "#load quantization config\n",
    "def load_transformer_quant_config(quant_config_path: str = \"./quant_config.json\",\n",
    "                                  norm_quant_config_path: str = \"./norm_quant_config.json\",\n",
    "                                  num_layers: int = 1) -> dict:\n",
    "    with open(quant_config_path, 'r') as f:\n",
    "        quant_config = json.load(f)\n",
    "    with open(norm_quant_config_path, 'r') as f:\n",
    "        norm_quant_config = json.load(f)\n",
    "    transformer_quant_config = {}\n",
    "    for i in range(num_layers):\n",
    "        transformer_quant_config[i] = copy.deepcopy(quant_config)\n",
    "    transformer_quant_config['norm'] = copy.deepcopy(norm_quant_config)\n",
    "    return transformer_quant_config\n",
    "\n",
    "\n",
    "transformer_quant_config = load_transformer_quant_config(num_layers=4)\n",
    "pprint(transformer_quant_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"eval_behavior\": shape (574, 140, 2), type \"<f4\">\n",
      "<HDF5 dataset \"eval_cond_idx\": shape (108,), type \"|O\">\n",
      "<HDF5 dataset \"eval_spikes_heldin\": shape (574, 140, 137), type \"<f2\">\n",
      "<HDF5 dataset \"eval_spikes_heldin_forward\": shape (574, 40, 137), type \"<f2\">\n",
      "<HDF5 dataset \"eval_spikes_heldout\": shape (574, 140, 45), type \"<f2\">\n",
      "<HDF5 dataset \"eval_spikes_heldout_forward\": shape (574, 40, 45), type \"<f2\">\n",
      "<HDF5 dataset \"psth\": shape (108, 140, 182), type \"<f4\">\n",
      "<HDF5 dataset \"train_behavior\": shape (1721, 140, 2), type \"<f4\">\n",
      "<HDF5 dataset \"train_cond_idx\": shape (108,), type \"|O\">\n",
      "<HDF5 dataset \"train_spikes_heldin\": shape (1721, 140, 137), type \"<f2\">\n",
      "<HDF5 dataset \"train_spikes_heldin_forward\": shape (1721, 40, 137), type \"<f2\">\n",
      "<HDF5 dataset \"train_spikes_heldout\": shape (1721, 140, 45), type \"<f2\">\n",
      "<HDF5 dataset \"train_spikes_heldout_forward\": shape (1721, 40, 45), type \"<f2\">\n",
      "torch.Size([574, 140, 137])\n",
      "torch.Size([574, 140, 45])\n",
      "torch.Size([574, 40, 137])\n",
      "torch.Size([574, 40, 45])\n",
      "torch.Size([574, 180, 182])\n",
      "torch.Size([574, 180, 182])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2127150/402605383.py:11: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  else h5file[key][()].astype(np.object) if key == 'eval_cond_idx'\n"
     ]
    }
   ],
   "source": [
    "from synchronizer import *\n",
    "from metrics import bits_per_spike\n",
    "import h5py\n",
    "import numpy as np\n",
    "target_path = './mc_maze_all.h5'\n",
    "variant = 'mc_maze'\n",
    "with h5py.File(target_path, 'r') as h5file:\n",
    "    for key in h5file.keys():\n",
    "        print(h5file[key])\n",
    "    target_dict = {f'{variant}': {key: h5file[key][()].astype(np.bool_) if key == 'train_decode_mask' or key == 'eval_decode_mask'\n",
    "                    else h5file[key][()].astype(np.object) if key == 'eval_cond_idx'\n",
    "                    else h5file[key][()].astype(np.int_) if key == 'eval_jitter'\n",
    "                    else h5file[key][()]\n",
    "                    for key in h5file.keys()\n",
    "                    }}\n",
    "spikes = target_dict['mc_maze']['eval_spikes_heldin'].astype(np.float32)\n",
    "spikes_heldout = target_dict['mc_maze']['eval_spikes_heldout'].astype(np.float32)\n",
    "heldin_forward = target_dict['mc_maze']['eval_spikes_heldin_forward'].astype(np.float32)\n",
    "heldout_forward = target_dict['mc_maze']['eval_spikes_heldout_forward'].astype(np.float32)\n",
    "import torch\n",
    "spikes = torch.tensor(spikes)\n",
    "spikes = spikes.to(torch.device('cpu'))\n",
    "print(spikes.shape)\n",
    "spikes_heldout = torch.tensor(spikes_heldout)\n",
    "spikes_heldout = spikes_heldout.to(torch.device('cpu'))\n",
    "print(spikes_heldout.shape)\n",
    "heldin_forward = torch.tensor(heldin_forward)\n",
    "heldin_forward = heldin_forward.to(torch.device('cpu'))\n",
    "print(heldin_forward.shape)\n",
    "heldout_forward = torch.tensor(heldout_forward)\n",
    "heldout_forward = heldout_forward.to(torch.device('cpu'))\n",
    "print(heldout_forward.shape)\n",
    "mask_labels = torch.cat([spikes, spikes_heldout], -1)\n",
    "src_forward = torch.cat([heldin_forward, heldout_forward], -1)\n",
    "mask_labels = torch.cat([mask_labels, src_forward], 1)\n",
    "print(mask_labels.shape)\n",
    "spike_forward = torch.cat([heldin_forward, heldout_forward], -1)\n",
    "spikes = torch.cat([spikes, torch.zeros_like(spikes_heldout)], -1)\n",
    "src = torch.cat([spikes, torch.zeros_like(spike_forward)], 1)\n",
    "print(src.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15293288230895996\n",
      "tensor(0.077368862926960)\n",
      "0.37271108393010516\n"
     ]
    }
   ],
   "source": [
    "model.to(torch.device('cpu'))\n",
    "model.eval()\n",
    "batch = 100\n",
    "import time\n",
    "with torch.no_grad():\n",
    "    x = model.embedder(src[0:batch].permute(1, 0, 2)) * model.scale\n",
    "    x = model.pos_encoder(x)\n",
    "    t1 = time.time()\n",
    "    torch_pred = model.transformer_encoder(x, mask=model._get_or_generate_context_mask(x))\n",
    "    t2 = time.time()\n",
    "    print(t2-t1)\n",
    "    #print(torch_pred)\n",
    "    pred_rates = model.decoder(torch_pred[0]).permute(1, 0, 2) # t x b x n\n",
    "    loss = model.classifier(pred_rates, mask_labels[0:batch])\n",
    "    torch_masked_loss = loss[mask_labels[0:batch] != -100]\n",
    "    torch_masked_loss = torch_masked_loss.mean()\n",
    "print(torch_masked_loss)\n",
    "print(bits_per_spike(pred_rates[:,:140,137:182].cpu().numpy(), spikes_heldout[:batch,:,:].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qmodel = QTransformerEncoder([QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[0], calibration=True, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[1], calibration=True, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[2], calibration=True, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[3], calibration=True, device='cpu')], \n",
    "                             4, \n",
    "                             QLayerNorm(182, quant_config=transformer_quant_config['norm'], calibration=True, device='cpu'),\n",
    "                             TorchQuantizer(bitwidth=18, int_bitwidth=6, signed=True, calibration=True, rounding='TRUNCATE', saturation='SAT'),\n",
    "                             dtype=torch.float64)\n",
    "qmodel.transfer_weights(model)\n",
    "qmodel.to(torch.device('cpu'))  \n",
    "model.eval()\n",
    "batch = 1\n",
    "#calibration\n",
    "with torch.no_grad():\n",
    "    x = model.embedder(src[0:batch].permute(1, 0, 2)) * model.scale\n",
    "    x = model.pos_encoder(x)\n",
    "    print(x.max())\n",
    "    print(x.min())  \n",
    "    qmodel.eval()\n",
    "    transformer_quant_config = calibrate_transformer(qmodel, transformer_quant_config, x.type(torch.float64).to(torch.device('cpu')), model._get_or_generate_context_mask(x))\n",
    "\n",
    "#transformer_quant_config[0]['norm1']['input']['int_bitwidth'] = 3\n",
    "pprint(transformer_quant_config)\n",
    "#save transformer_quant_config\n",
    "torch.save(transformer_quant_config, './transformer_quant_config.pth')\n",
    "#load transformer_quant_config\n",
    "transformer_quant_config = torch.load('./transformer_quant_config.pth')\n",
    "pprint(transformer_quant_config)\n",
    "#qmodel = QTransformerEncoder([QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[0], calibration=False, device='cpu'),\n",
    "#                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[1], calibration=False, device='cpu'),\n",
    "#                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[2], calibration=False, device='cpu'),\n",
    "#                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[3], calibration=False, device='cpu')], \n",
    "#                             4, \n",
    "#                             QLayerNorm(182, quant_config=transformer_quant_config['norm'], calibration=False, device='cpu'),\n",
    "#                             TorchQuantizer(bitwidth=18, int_bitwidth=6, signed=True, calibration=False),\n",
    "#                             dtype=torch.float64)\n",
    "#qmodel.transfer_weights(model)\n",
    "#qmodel.to(torch.device('cpu'))\n",
    "#batch = 547\n",
    "#model.eval()\n",
    "#with torch.no_grad():\n",
    "#    x = model.embedder(src[0:batch].permute(1, 0, 2)) * model.scale\n",
    "#    x = model.pos_encoder(x)\n",
    "#    qmodel.eval()\n",
    "#    qy = qmodel(x.type(torch.float64).to(torch.device('cpu')), mask=model._get_or_generate_context_mask(x))\n",
    "#    print(qy)\n",
    "#    print(x.shape)\n",
    "#    y = model.transformer_encoder(x, mask=model._get_or_generate_context_mask(x))\n",
    "#    print(y)\n",
    "#    pred_rates = model.decoder(qy.type(torch.float32)).permute(1, 0, 2) # t x b x n\n",
    "#    loss = model.classifier(pred_rates, mask_labels[0:batch])\n",
    "#    torch_masked_loss = loss[mask_labels[0:batch] != -100]\n",
    "#    torch_masked_loss = torch_masked_loss.mean()\n",
    "#    print(torch_masked_loss)\n",
    "#    print(bits_per_spike(pred_rates[:,:140,137:182].cpu().numpy(), spikes_heldout[0:batch,:,:].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDT4HLS(\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=182, out_features=182, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=182, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.3946451938505568, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=182, bias=True)\n",
      "        (norm1): LayerNorm((182,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((182,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.3946451938505568, inplace=False)\n",
      "        (dropout2): Dropout(p=0.3946451938505568, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((182,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "dict_keys(['layers_0_norm1.Precision.var_table', 'layers_0_norm1.VarTableSize', 'layers_0_norm1.Precision.result', 'layers_0_self_attn.Precision.exp_table', 'layers_0_self_attn.ExpTableSize', 'layers_0_self_attn.Precision.inv_table', 'layers_0_self_attn.InvTableSize', 'layers_0_self_attn.Precision.in_proj_out', 'layers_0_self_attn.Precision.out_proj_in', 'layers_0_self_attn.Precision.in_proj_weight', 'layers_0_self_attn.Precision.out_proj_weight', 'layers_0_self_attn.Precision.result', 'layers_0_add1.Precision.result', 'layers_0_norm2.Precision.var_table', 'layers_0_norm2.VarTableSize', 'layers_0_norm2.Precision.result', 'layers_0_ffn.Precision.in_proj_weight', 'layers_0_ffn.Precision.out_proj_weight', 'layers_0_ffn.Precision.hidden', 'layers_0_ffn.Precision.result', 'layers_0_add2.Precision.result', 'layers_1_norm1.Precision.var_table', 'layers_1_norm1.VarTableSize', 'layers_1_norm1.Precision.result', 'layers_1_self_attn.Precision.exp_table', 'layers_1_self_attn.ExpTableSize', 'layers_1_self_attn.Precision.inv_table', 'layers_1_self_attn.InvTableSize', 'layers_1_self_attn.Precision.in_proj_out', 'layers_1_self_attn.Precision.out_proj_in', 'layers_1_self_attn.Precision.in_proj_weight', 'layers_1_self_attn.Precision.out_proj_weight', 'layers_1_self_attn.Precision.result', 'layers_1_add1.Precision.result', 'layers_1_norm2.Precision.var_table', 'layers_1_norm2.VarTableSize', 'layers_1_norm2.Precision.result', 'layers_1_ffn.Precision.in_proj_weight', 'layers_1_ffn.Precision.out_proj_weight', 'layers_1_ffn.Precision.hidden', 'layers_1_ffn.Precision.result', 'layers_1_add2.Precision.result', 'layers_2_norm1.Precision.var_table', 'layers_2_norm1.VarTableSize', 'layers_2_norm1.Precision.result', 'layers_2_self_attn.Precision.exp_table', 'layers_2_self_attn.ExpTableSize', 'layers_2_self_attn.Precision.inv_table', 'layers_2_self_attn.InvTableSize', 'layers_2_self_attn.Precision.in_proj_out', 'layers_2_self_attn.Precision.out_proj_in', 'layers_2_self_attn.Precision.in_proj_weight', 'layers_2_self_attn.Precision.out_proj_weight', 'layers_2_self_attn.Precision.result', 'layers_2_add1.Precision.result', 'layers_2_norm2.Precision.var_table', 'layers_2_norm2.VarTableSize', 'layers_2_norm2.Precision.result', 'layers_2_ffn.Precision.in_proj_weight', 'layers_2_ffn.Precision.out_proj_weight', 'layers_2_ffn.Precision.hidden', 'layers_2_ffn.Precision.result', 'layers_2_add2.Precision.result', 'layers_3_norm1.Precision.var_table', 'layers_3_norm1.VarTableSize', 'layers_3_norm1.Precision.result', 'layers_3_self_attn.Precision.exp_table', 'layers_3_self_attn.ExpTableSize', 'layers_3_self_attn.Precision.inv_table', 'layers_3_self_attn.InvTableSize', 'layers_3_self_attn.Precision.in_proj_out', 'layers_3_self_attn.Precision.out_proj_in', 'layers_3_self_attn.Precision.in_proj_weight', 'layers_3_self_attn.Precision.out_proj_weight', 'layers_3_self_attn.Precision.result', 'layers_3_add1.Precision.result', 'layers_3_norm2.Precision.var_table', 'layers_3_norm2.VarTableSize', 'layers_3_norm2.Precision.result', 'layers_3_ffn.Precision.in_proj_weight', 'layers_3_ffn.Precision.out_proj_weight', 'layers_3_ffn.Precision.hidden', 'layers_3_ffn.Precision.result', 'layers_3_add2.Precision.result', 'norm.Precision.var_table', 'norm.VarTableSize', 'norm.Precision.result', 'layers_0_norm1.Precision.bias', 'layers_0_norm1.Precision.scale', 'layers_0_norm1.Precision.mean', 'layers_0_self_attn.Precision.in_proj_bias', 'layers_0_self_attn.Precision.out_proj_bias', 'layers_0_self_attn.Precision.row_sum', 'layers_0_ffn.Precision.in_proj_bias', 'layers_0_ffn.Precision.out_proj_bias', 'layers_0_norm2.Precision.bias', 'layers_0_norm2.Precision.scale', 'layers_0_norm2.Precision.mean', 'layers_1_norm1.Precision.bias', 'layers_1_norm1.Precision.scale', 'layers_1_norm1.Precision.mean', 'layers_1_self_attn.Precision.in_proj_bias', 'layers_1_self_attn.Precision.out_proj_bias', 'layers_1_self_attn.Precision.row_sum', 'layers_1_ffn.Precision.in_proj_bias', 'layers_1_ffn.Precision.out_proj_bias', 'layers_1_norm2.Precision.bias', 'layers_1_norm2.Precision.scale', 'layers_1_norm2.Precision.mean', 'layers_2_norm1.Precision.bias', 'layers_2_norm1.Precision.scale', 'layers_2_norm1.Precision.mean', 'layers_2_self_attn.Precision.in_proj_bias', 'layers_2_self_attn.Precision.out_proj_bias', 'layers_2_self_attn.Precision.row_sum', 'layers_2_ffn.Precision.in_proj_bias', 'layers_2_ffn.Precision.out_proj_bias', 'layers_2_norm2.Precision.bias', 'layers_2_norm2.Precision.scale', 'layers_2_norm2.Precision.mean', 'layers_3_norm1.Precision.bias', 'layers_3_norm1.Precision.scale', 'layers_3_norm1.Precision.mean', 'layers_3_self_attn.Precision.in_proj_bias', 'layers_3_self_attn.Precision.out_proj_bias', 'layers_3_self_attn.Precision.row_sum', 'layers_3_ffn.Precision.in_proj_bias', 'layers_3_ffn.Precision.out_proj_bias', 'layers_3_norm2.Precision.bias', 'layers_3_norm2.Precision.scale', 'layers_3_norm2.Precision.mean', 'norm.Precision.bias', 'norm.Precision.scale', 'norm.Precision.mean'])\n",
      "TTTTTTTTTopology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'transformer_quant_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m config \u001b[38;5;241m=\u001b[39m hls4ml\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mconfig_from_pytorch_model(model4hls, \n\u001b[1;32m     87\u001b[0m                                                 granularity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     88\u001b[0m                                                 backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVitis\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m                                                 inputs_channel_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     92\u001b[0m                                                 transpose_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m#config = sync_hls_config(config, state)\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m transformer_quant_config \u001b[38;5;241m=\u001b[39m sync_quant_config(\u001b[43mtransformer_quant_config\u001b[49m, config,state)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[1;32m     96\u001b[0m pprint(transformer_quant_config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformer_quant_config' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "from synchronizer import *\n",
    "\n",
    "class NDT4HLS(torch.nn.Module):\n",
    "    def __init__(self, config, trial_length, num_neurons, device, max_spikes):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.trial_length = trial_length\n",
    "        self.num_neurons = num_neurons\n",
    "        self.device = device\n",
    "\n",
    "        # TODO buffer\n",
    "        if config.FULL_CONTEXT:\n",
    "            self.src_mask = None\n",
    "        else:\n",
    "            self.src_mask = {} # multi-GPU masks\n",
    "        if config.EMBED_DIM == 0:\n",
    "            self.num_input = num_neurons\n",
    "        else:\n",
    "            self.num_input = config.EMBED_DIM * num_neurons\n",
    "\n",
    "        self._init_transformer()\n",
    "        self.src_mask = self._get_or_generate_context_mask(torch.zeros(self.trial_length, self.trial_length, device=device))\n",
    "        self.padding_mask = torch.randint(0, 2, (self.trial_length, self.trial_length), device=device).bool()\n",
    "        #self.init_weights()\n",
    "\n",
    "    def _init_transformer(self):\n",
    "        norm = nn.LayerNorm(self.num_input)\n",
    "        #encoder_layer = nn.TransformerEncoderLayer(d_model=self.num_input, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=self.num_input, \n",
    "                                       nhead=self.config.NUM_HEADS,\n",
    "                                       dim_feedforward=self.config.HIDDEN_SIZE,\n",
    "                                       dropout=self.config.DROPOUT,\n",
    "                                       activation=self.config.ACTIVATION,\n",
    "                                       norm_first=self.config.PRE_NORM,\n",
    "                                       device=self.device),\n",
    "            self.config.NUM_LAYERS,\n",
    "            norm=norm\n",
    "        )\n",
    "    \n",
    "    def _get_or_generate_context_mask(self, src, do_convert=True, expose_ic=True):\n",
    "        if self.config.FULL_CONTEXT:\n",
    "            return None\n",
    "        if str(src.device) in self.src_mask:\n",
    "            return self.src_mask[str(src.device)]\n",
    "        size = src.size(0) # T\n",
    "        context_forward = self.config.CONTEXT_FORWARD\n",
    "        if self.config.CONTEXT_FORWARD < 0:\n",
    "            context_forward = size\n",
    "        mask = (torch.triu(torch.ones(size, size, device=src.device), diagonal=-context_forward) == 1).transpose(0, 1)\n",
    "        if self.config.CONTEXT_BACKWARD > 0:\n",
    "            back_mask = (torch.triu(torch.ones(size, size, device=src.device), diagonal=-self.config.CONTEXT_BACKWARD) == 1)\n",
    "            mask = mask & back_mask\n",
    "        if expose_ic and self.config.CONTEXT_WRAP_INITIAL and self.config.CONTEXT_BACKWARD > 0:\n",
    "            # Expose initial segment for IC\n",
    "            initial_mask = torch.triu(torch.ones(self.config.CONTEXT_BACKWARD, self.config.CONTEXT_BACKWARD, device=src.device))\n",
    "            mask[:self.config.CONTEXT_BACKWARD, :self.config.CONTEXT_BACKWARD] |= initial_mask\n",
    "        mask = mask.float()\n",
    "        def binary_mask_to_attn_mask(x):\n",
    "            return x.float().masked_fill(x == 0, float('-inf')).masked_fill(x == 1, float(0.0))\n",
    "        if do_convert:\n",
    "            mask = binary_mask_to_attn_mask(mask)\n",
    "        self.src_mask[str(src.device)] = mask\n",
    "        return self.src_mask[str(src.device)]\n",
    "\n",
    "    def forward(self, src):  \n",
    "        #src_mask = self._get_or_generate_context_mask(src)\n",
    "        output = self.transformer_encoder(src, mask=self.src_mask)\n",
    "        return output\n",
    "    \n",
    "model4hls = torch.load('./NDT4HLS.pth', map_location=torch.device('cpu'))\n",
    "print(model4hls)\n",
    "\n",
    "BRAMstate = gen_init_BRAMaware_state(4)\n",
    "DSPstate = gen_init_nonBRAMaware_state(4)\n",
    "#merge BRAMstate and DSPstate\n",
    "state = {**BRAMstate, **DSPstate}\n",
    "print(state.keys())\n",
    "#state['layers_0_norm2.Precision.result'] = 18\n",
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_pytorch_model(model4hls, \n",
    "                                                granularity='name',\n",
    "                                                backend='Vitis',\n",
    "                                                input_shapes=[[1, 180, 182]], \n",
    "                                                default_precision='ap_fixed<18,6,AP_RND_CONV>', \n",
    "                                                inputs_channel_last=True, \n",
    "                                                transpose_outputs=False)\n",
    "#config = sync_hls_config(config, state)\n",
    "transformer_quant_config = sync_quant_config(transformer_quant_config, config,state)\n",
    "from pprint import pprint\n",
    "pprint(transformer_quant_config)\n",
    "pprint(config)\n",
    "torch.save(model4hls, './model4hls.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hls4ml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrm -rf ./q.txt ./k.txt ./v.txt ./query.txt ./norm_in.txt ./norm_out.txt ./ffn_hidden.txt ./ffn_out.txt ./xvar_in.txt ./xvar_out.txt ./xnorm_133.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrm -rf ./xnorm_133.txt ./x_debug.txt ./xnorm_133_before.txt ./xsum.txt ./xmean.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m hls_model \u001b[38;5;241m=\u001b[39m \u001b[43mhls4ml\u001b[49m\u001b[38;5;241m.\u001b[39mconverters\u001b[38;5;241m.\u001b[39mconvert_from_pytorch_model(\n\u001b[1;32m      5\u001b[0m                                                             model4hls,\n\u001b[1;32m      6\u001b[0m                                                             [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m180\u001b[39m, \u001b[38;5;241m182\u001b[39m]],\n\u001b[1;32m      7\u001b[0m                                                             output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./hls/ndt_calibrate\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m                                                             project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmyproject\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                                             backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVitis\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m                                                             \u001b[38;5;66;03m#part='xcu250-figd2104-2L-e',\u001b[39;00m\n\u001b[1;32m     11\u001b[0m                                                             part\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxcu55c-fsvh2892-2L-e\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m                                                             \u001b[38;5;66;03m#board='alveo-u55c',\u001b[39;00m\n\u001b[1;32m     13\u001b[0m                                                             hls_config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m     14\u001b[0m                                                             io_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mio_tile_stream\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m                                                         )\n\u001b[1;32m     16\u001b[0m hls_model\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[1;32m     17\u001b[0m transformer_quant_config \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./transformer_quant_config.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hls4ml' is not defined"
     ]
    }
   ],
   "source": [
    "!rm -rf ./hls/ndt_calibrate\n",
    "!rm -rf ./q.txt ./k.txt ./v.txt ./query.txt ./norm_in.txt ./norm_out.txt ./ffn_hidden.txt ./ffn_out.txt ./xvar_in.txt ./xvar_out.txt ./xnorm_133.txt\n",
    "!rm -rf ./xnorm_133.txt ./x_debug.txt ./xnorm_133_before.txt ./xsum.txt ./xmean.txt\n",
    "hls_model = hls4ml.converters.convert_from_pytorch_model(\n",
    "                                                            model4hls,\n",
    "                                                            [[1, 180, 182]],\n",
    "                                                            output_dir='./hls/ndt_calibrate',\n",
    "                                                            project_name='myproject',\n",
    "                                                            backend='Vitis',\n",
    "                                                            #part='xcu250-figd2104-2L-e',\n",
    "                                                            part='xcu55c-fsvh2892-2L-e',\n",
    "                                                            #board='alveo-u55c',\n",
    "                                                            hls_config=config,\n",
    "                                                            io_type='io_tile_stream',\n",
    "                                                        )\n",
    "hls_model.compile()\n",
    "transformer_quant_config = torch.load('./transformer_quant_config.pth')\n",
    "qmodel = QTransformerEncoder([QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[0], calibration=False, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[1], calibration=False, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[2], calibration=False, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[3], calibration=False, device='cpu')], \n",
    "                             4, \n",
    "                             QLayerNorm(182, quant_config=transformer_quant_config['norm'], calibration=False, device='cpu'),\n",
    "                             TorchQuantizer(bitwidth=18, int_bitwidth=6, signed=True, calibration=False),\n",
    "                             dtype=torch.float64)\n",
    "qmodel.transfer_weights(model)\n",
    "qmodel.to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingchiyang/anaconda3/envs/auto-hls4ml/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QTransformerEncoder(\n",
       "  (layers): ModuleList(\n",
       "    (0-3): 4 x QTransformerEncoderLayer(\n",
       "      (self_attn): QFlashMultiheadAttention(\n",
       "        (out_proj): QLinear(\n",
       "          in_features=182, out_features=182, bias=True\n",
       "          (weight_qtzr): TorchQuantizer()\n",
       "          (bias_qtzr): TorchQuantizer()\n",
       "          (input_qtzr): TorchQuantizer()\n",
       "          (output_qtzr): TorchQuantizer()\n",
       "        )\n",
       "        (in_proj): QLinear(\n",
       "          in_features=182, out_features=546, bias=True\n",
       "          (weight_qtzr): TorchQuantizer()\n",
       "          (bias_qtzr): TorchQuantizer()\n",
       "          (input_qtzr): TorchQuantizer()\n",
       "          (output_qtzr): TorchQuantizer()\n",
       "        )\n",
       "        (scale_qtzr): TorchQuantizer()\n",
       "        (row_sum_qtzr): TorchQuantizer()\n",
       "        (exp_input_qtzr): TorchQuantizer()\n",
       "        (exp_output_qtzr): TorchQuantizer()\n",
       "        (inv_input_qtzr): TorchQuantizer()\n",
       "        (inv_output_qtzr): TorchQuantizer()\n",
       "        (attn_out_qtzr): TorchQuantizer()\n",
       "      )\n",
       "      (linear1): Linear(in_features=182, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (linear2): Linear(in_features=128, out_features=182, bias=True)\n",
       "      (norm1): QLayerNorm(\n",
       "        (182,), eps=1e-05, elementwise_affine=True\n",
       "        (input_qtzr): TorchQuantizer()\n",
       "        (scale_qtzr): TorchQuantizer()\n",
       "        (bias_qtzr): TorchQuantizer()\n",
       "        (output_qtzr): TorchQuantizer()\n",
       "        (mean_qtzr): TorchQuantizer()\n",
       "        (var_input_qtzr): TorchQuantizer()\n",
       "        (var_output_qtzr): TorchQuantizer()\n",
       "        (dim_qtzr): TorchQuantizer()\n",
       "      )\n",
       "      (norm2): QLayerNorm(\n",
       "        (182,), eps=1e-05, elementwise_affine=True\n",
       "        (input_qtzr): TorchQuantizer()\n",
       "        (scale_qtzr): TorchQuantizer()\n",
       "        (bias_qtzr): TorchQuantizer()\n",
       "        (output_qtzr): TorchQuantizer()\n",
       "        (mean_qtzr): TorchQuantizer()\n",
       "        (var_input_qtzr): TorchQuantizer()\n",
       "        (var_output_qtzr): TorchQuantizer()\n",
       "        (dim_qtzr): TorchQuantizer()\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (feedforward): QFeedForward(\n",
       "        (in_proj): QLinear(\n",
       "          in_features=182, out_features=128, bias=True\n",
       "          (weight_qtzr): TorchQuantizer()\n",
       "          (bias_qtzr): TorchQuantizer()\n",
       "          (input_qtzr): TorchQuantizer()\n",
       "          (output_qtzr): TorchQuantizer()\n",
       "        )\n",
       "        (activation): ReLU()\n",
       "        (out_proj): QLinear(\n",
       "          in_features=128, out_features=182, bias=True\n",
       "          (weight_qtzr): TorchQuantizer()\n",
       "          (bias_qtzr): TorchQuantizer()\n",
       "          (input_qtzr): TorchQuantizer()\n",
       "          (output_qtzr): TorchQuantizer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): QLayerNorm(\n",
       "    (182,), eps=1e-05, elementwise_affine=True\n",
       "    (input_qtzr): TorchQuantizer()\n",
       "    (scale_qtzr): TorchQuantizer()\n",
       "    (bias_qtzr): TorchQuantizer()\n",
       "    (output_qtzr): TorchQuantizer()\n",
       "    (mean_qtzr): TorchQuantizer()\n",
       "    (var_input_qtzr): TorchQuantizer()\n",
       "    (var_output_qtzr): TorchQuantizer()\n",
       "    (dim_qtzr): TorchQuantizer()\n",
       "  )\n",
       "  (input_qtzr): TorchQuantizer()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantizers import *\n",
    "transformer_quant_config = torch.load('./transformer_quant_config.pth')\n",
    "qmodel = QTransformerEncoder([QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[0], calibration=False, device='cpu'),\n",
    "                                          QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[1], calibration=False, device='cpu'),\n",
    "                                          QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[2], calibration=False, device='cpu'),\n",
    "                                          QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[3], calibration=False, device='cpu')], \n",
    "                                         4, \n",
    "                                         QLayerNorm(182, quant_config=transformer_quant_config['norm'], calibration=False, device='cpu'),\n",
    "                                         TorchQuantizer(bitwidth=18, int_bitwidth=7, signed=True, calibration=False),\n",
    "                                         dtype=torch.float64)\n",
    "qmodel.transfer_weights(model)\n",
    "qmodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.225999474525452, -0.071351677179337,  0.190537929534912,\n",
       "          ...,  0.218532174825668, -0.028859568759799,\n",
       "         -0.226950243115425],\n",
       "        [-0.141355514526367,  0.459919631481171, -0.306175261735916,\n",
       "          ..., -0.144744291901588, -0.002659732243046,\n",
       "          0.185846552252769],\n",
       "        [ 0.191516518592834,  0.366369456052780, -0.022614795714617,\n",
       "          ..., -0.073019221425056,  0.261426836252213,\n",
       "         -0.243765309453011],\n",
       "        ...,\n",
       "        [-0.526205003261566, -0.013391474261880,  0.267182588577271,\n",
       "          ..., -0.132935285568237,  0.296467602252960,\n",
       "          0.135996982455254],\n",
       "        [-0.237213551998138, -0.300363391637802,  0.430698931217194,\n",
       "          ...,  0.064543493092060, -0.056618712842464,\n",
       "          0.004697725176811],\n",
       "        [ 0.026527639478445,  0.110893569886684, -0.038346275687218,\n",
       "          ...,  0.197500541806221,  0.294359147548676,\n",
       "          0.037339907139540]], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer_encoder.layers[0].self_attn.in_proj_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.225999474525452, -0.071351677179337,  0.190537929534912,\n",
       "          ...,  0.218532174825668, -0.028859568759799,\n",
       "         -0.226950243115425],\n",
       "        [-0.141355514526367,  0.459919631481171, -0.306175261735916,\n",
       "          ..., -0.144744291901588, -0.002659732243046,\n",
       "          0.185846552252769],\n",
       "        [ 0.191516518592834,  0.366369456052780, -0.022614795714617,\n",
       "          ..., -0.073019221425056,  0.261426836252213,\n",
       "         -0.243765309453011],\n",
       "        ...,\n",
       "        [-0.526205003261566, -0.013391474261880,  0.267182588577271,\n",
       "          ..., -0.132935285568237,  0.296467602252960,\n",
       "          0.135996982455254],\n",
       "        [-0.237213551998138, -0.300363391637802,  0.430698931217194,\n",
       "          ...,  0.064543493092060, -0.056618712842464,\n",
       "          0.004697725176811],\n",
       "        [ 0.026527639478445,  0.110893569886684, -0.038346275687218,\n",
       "          ...,  0.197500541806221,  0.294359147548676,\n",
       "          0.037339907139540]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmodel.eval()\n",
    "qmodel.layer_list[0].self_attn.in_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.167724609375000e-02, -4.379653930664062e-02,\n",
      "          -3.646850585937500e-02,  ...,\n",
      "          -3.868103027343750e-03,  7.400512695312500e-04,\n",
      "          -2.618789672851562e-02],\n",
      "         [-1.570587158203125e-01, -3.460311889648438e-02,\n",
      "          -1.435470581054688e-02,  ...,\n",
      "           4.227828979492188e-02, -8.401107788085938e-02,\n",
      "           3.317260742187500e-02],\n",
      "         [-1.748657226562500e-01,  8.018493652343750e-03,\n",
      "          -1.191711425781250e-02,  ...,\n",
      "           6.306076049804688e-02, -1.088867187500000e-01,\n",
      "           8.113861083984375e-03],\n",
      "         ...,\n",
      "         [-1.449928283691406e-01,  3.013992309570312e-02,\n",
      "          -4.918670654296875e-02,  ...,\n",
      "           3.261184692382812e-02, -1.823768615722656e-01,\n",
      "           1.250839233398438e-02],\n",
      "         [ 7.453536987304688e-02, -2.826690673828125e-03,\n",
      "          -1.046752929687500e-02,  ...,\n",
      "           4.787445068359375e-03, -3.077316284179688e-02,\n",
      "          -2.782821655273438e-02],\n",
      "         [-2.764892578125000e-02, -3.554534912109375e-02,\n",
      "          -1.020812988281250e-02,  ...,\n",
      "          -8.354187011718750e-03, -1.198196411132812e-02,\n",
      "          -1.091003417968750e-02]],\n",
      "\n",
      "        [[ 3.171920776367188e-02, -4.382705688476562e-02,\n",
      "          -3.642272949218750e-02,  ...,\n",
      "          -1.716613769531250e-04,  6.935119628906250e-03,\n",
      "          -2.589035034179688e-02],\n",
      "         [-1.506881713867188e-01, -3.532409667968750e-02,\n",
      "          -1.266098022460938e-02,  ...,\n",
      "           4.444122314453125e-02, -8.481216430664062e-02,\n",
      "           3.346633911132812e-02],\n",
      "         [-1.817703247070312e-01,  4.516601562500000e-03,\n",
      "          -1.165771484375000e-02,  ...,\n",
      "           6.335449218750000e-02, -1.104698181152344e-01,\n",
      "           8.518218994140625e-03],\n",
      "         ...,\n",
      "         [-1.527404785156250e-01,  2.731323242187500e-02,\n",
      "          -5.474090576171875e-02,  ...,\n",
      "           2.738952636718750e-02, -1.771965026855469e-01,\n",
      "           1.551818847656250e-02],\n",
      "         [ 7.360458374023438e-02, -1.123428344726562e-02,\n",
      "          -8.766174316406250e-03,  ...,\n",
      "           3.387451171875000e-03, -2.622604370117188e-02,\n",
      "          -2.967453002929688e-02],\n",
      "         [-2.893829345703125e-02, -3.933334350585938e-02,\n",
      "          -9.891510009765625e-03,  ...,\n",
      "          -8.808135986328125e-03, -1.092529296875000e-02,\n",
      "          -1.133346557617188e-02]],\n",
      "\n",
      "        [[ 3.128051757812500e-02, -4.307174682617188e-02,\n",
      "          -3.714370727539062e-02,  ...,\n",
      "          -4.043579101562500e-04,  5.920410156250000e-03,\n",
      "          -2.597045898437500e-02],\n",
      "         [-1.548805236816406e-01, -3.153610229492188e-02,\n",
      "          -1.327896118164062e-02,  ...,\n",
      "           4.632186889648438e-02, -8.251953125000000e-02,\n",
      "           3.251647949218750e-02],\n",
      "         [-1.811180114746094e-01,  6.504058837890625e-03,\n",
      "          -1.318740844726562e-02,  ...,\n",
      "           6.528854370117188e-02, -1.072998046875000e-01,\n",
      "           9.643554687500000e-03],\n",
      "         ...,\n",
      "         [-1.526794433593750e-01,  2.569198608398438e-02,\n",
      "          -5.564498901367188e-02,  ...,\n",
      "           2.630615234375000e-02, -1.786117553710938e-01,\n",
      "           1.387405395507812e-02],\n",
      "         [ 7.334899902343750e-02, -1.085281372070312e-02,\n",
      "          -8.815765380859375e-03,  ...,\n",
      "           2.880096435546875e-03, -2.544021606445312e-02,\n",
      "          -2.980041503906250e-02],\n",
      "         [-2.848815917968750e-02, -3.562927246093750e-02,\n",
      "          -1.026535034179688e-02,  ...,\n",
      "          -9.033203125000000e-03, -1.192092895507812e-02,\n",
      "          -1.119613647460938e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.777099609375000e-03,  1.918792724609375e-02,\n",
      "           1.566085815429688e-01,  ...,\n",
      "          -1.139945983886719e-01,  6.430053710937500e-02,\n",
      "          -4.886245727539062e-02],\n",
      "         [ 2.837753295898438e-02,  1.241531372070312e-01,\n",
      "          -9.471893310546875e-03,  ...,\n",
      "           3.901672363281250e-02, -3.743743896484375e-02,\n",
      "           3.794479370117188e-02],\n",
      "         [-3.106307983398438e-02,  3.701019287109375e-02,\n",
      "          -2.345275878906250e-02,  ...,\n",
      "          -2.508163452148438e-02, -9.562683105468750e-02,\n",
      "           2.637825012207031e-01],\n",
      "         ...,\n",
      "         [-2.460479736328125e-02,  9.249877929687500e-02,\n",
      "          -1.155853271484375e-02,  ...,\n",
      "          -6.245803833007812e-02,  3.190231323242188e-02,\n",
      "           1.739921569824219e-01],\n",
      "         [ 2.458572387695312e-02, -5.695343017578125e-03,\n",
      "          -3.131866455078125e-03,  ...,\n",
      "           8.831024169921875e-03,  5.233764648437500e-03,\n",
      "           1.189155578613281e-01],\n",
      "         [ 1.881790161132812e-02, -1.063156127929688e-02,\n",
      "           3.459930419921875e-03,  ...,\n",
      "          -5.641937255859375e-03,  4.711151123046875e-03,\n",
      "           1.476211547851562e-01]],\n",
      "\n",
      "        [[-2.910614013671875e-03,  1.952362060546875e-02,\n",
      "           1.555023193359375e-01,  ...,\n",
      "          -1.109275817871094e-01,  6.490325927734375e-02,\n",
      "          -4.821014404296875e-02],\n",
      "         [ 2.700424194335938e-02,  1.225852966308594e-01,\n",
      "          -8.956909179687500e-03,  ...,\n",
      "           3.462982177734375e-02, -3.778457641601562e-02,\n",
      "           3.986740112304688e-02],\n",
      "         [-3.095245361328125e-02,  3.673934936523438e-02,\n",
      "          -2.354431152343750e-02,  ...,\n",
      "          -2.749633789062500e-02, -9.392166137695312e-02,\n",
      "           2.621841430664062e-01],\n",
      "         ...,\n",
      "         [-2.375411987304688e-02,  9.013366699218750e-02,\n",
      "          -1.045227050781250e-02,  ...,\n",
      "          -6.485748291015625e-02,  3.186416625976562e-02,\n",
      "           1.715812683105469e-01],\n",
      "         [ 2.211761474609375e-02, -6.759643554687500e-03,\n",
      "          -2.624511718750000e-03,  ...,\n",
      "           4.394531250000000e-03,  6.134033203125000e-03,\n",
      "           1.155090332031250e-01],\n",
      "         [ 3.096389770507812e-02, -1.183319091796875e-02,\n",
      "           1.279067993164062e-02,  ...,\n",
      "           1.249313354492188e-02,  1.642608642578125e-02,\n",
      "           1.675910949707031e-01]],\n",
      "\n",
      "        [[-8.441925048828125e-03,  1.939773559570312e-02,\n",
      "           1.542434692382812e-01,  ...,\n",
      "          -1.093025207519531e-01,  5.974197387695312e-02,\n",
      "          -5.155181884765625e-02],\n",
      "         [ 2.671051025390625e-02,  1.201019287109375e-01,\n",
      "          -9.361267089843750e-03,  ...,\n",
      "           3.479385375976562e-02, -4.077148437500000e-02,\n",
      "           4.453659057617188e-02],\n",
      "         [-3.121566772460938e-02,  3.721237182617188e-02,\n",
      "          -2.365112304687500e-02,  ...,\n",
      "          -2.788925170898438e-02, -9.325027465820312e-02,\n",
      "           2.602119445800781e-01],\n",
      "         ...,\n",
      "         [-2.145004272460938e-02,  9.162902832031250e-02,\n",
      "          -8.274078369140625e-03,  ...,\n",
      "          -6.433486938476562e-02,  3.269195556640625e-02,\n",
      "           1.651535034179688e-01],\n",
      "         [ 2.154159545898438e-02, -6.408691406250000e-03,\n",
      "          -2.178192138671875e-03,  ...,\n",
      "           5.676269531250000e-03,  5.290985107421875e-03,\n",
      "           1.158294677734375e-01],\n",
      "         [ 2.181625366210938e-02, -1.330184936523438e-02,\n",
      "           5.378723144531250e-03,  ...,\n",
      "           1.865386962890625e-03,  7.061004638671875e-03,\n",
      "           1.531028747558594e-01]]], dtype=torch.float64)\n",
      "tensor(0.080655165016651)\n",
      "0.30072439174978477\n"
     ]
    }
   ],
   "source": [
    "batch = 10\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x = model.embedder(src[0:batch].permute(1, 0, 2)) * model.scale\n",
    "    x = model.pos_encoder(x)\n",
    "    qmodel.eval()\n",
    "    x.type(torch.float64).to(torch.device('cpu'))\n",
    "    #save x\n",
    "    qy = qmodel(x.type(torch.float64), mask=model._get_or_generate_context_mask(x))\n",
    "    #save qmodel\n",
    "    #torch.save(qmodel, './qmodel.pth')\n",
    "    print(qy)\n",
    "    #hls_y = hls_model.predict(x.cpu().numpy())\n",
    "    #print(hls_y)\n",
    "    pred_rates = model.decoder(qy.type(torch.float32)).permute(1, 0, 2) # t x b x n\n",
    "    loss = model.classifier(pred_rates, mask_labels[0:batch])\n",
    "    torch_masked_loss = loss[mask_labels[0:batch] != -100]\n",
    "    torch_masked_loss = torch_masked_loss.mean()\n",
    "print(torch_masked_loss)\n",
    "print(bits_per_spike(pred_rates[:,:140,137:182].cpu().numpy(), spikes_heldout[:batch,:,:].cpu().numpy()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_config dict_keys(['state_dict', 'optim_state', 'lr_scheduler', 'config', 'best_val', 'best_unmasked_val', 'best_r2', 'max_spikes', 'num_neurons', 'trial_length', 'extra_state'])\n",
      "TTTTTTTTTopology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "layers_0_norm1.Precision.var_table is changed to 15\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingchiyang/anaconda3/envs/auto-hls4ml/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingchiyang/anaconda3/envs/auto-hls4ml/lib/python3.9/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers_0_norm1.VarTableSize is changed to 15\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_norm1.Precision.result is changed to 15\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_self_attn.Precision.exp_table is changed to 20\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_self_attn.ExpTableSize is changed to 7\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_self_attn.Precision.inv_table is changed to 13\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_self_attn.InvTableSize is changed to 15\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_self_attn.Precision.in_proj_out is changed to 19\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_self_attn.Precision.out_proj_in is changed to 22\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_self_attn.Precision.in_proj_weight is changed to 23\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_self_attn.Precision.out_proj_weight is changed to 16\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_self_attn.Precision.result is changed to 23\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_add1.Precision.result is changed to 16\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_norm2.Precision.var_table is changed to 21\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_norm2.VarTableSize is changed to 12\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_norm2.Precision.result is changed to 21\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_ffn.Precision.in_proj_weight is changed to 23\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_ffn.Precision.out_proj_weight is changed to 17\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_ffn.Precision.hidden is changed to 19\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_ffn.Precision.result is changed to 15\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_0_add2.Precision.result is changed to 21\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_norm1.Precision.var_table is changed to 15\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_norm1.VarTableSize is changed to 11\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_norm1.Precision.result is changed to 23\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_self_attn.Precision.exp_table is changed to 21\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_self_attn.ExpTableSize is changed to 14\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_self_attn.Precision.inv_table is changed to 22\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_self_attn.InvTableSize is changed to 8\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_self_attn.Precision.in_proj_out is changed to 14\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_self_attn.Precision.out_proj_in is changed to 19\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_self_attn.Precision.in_proj_weight is changed to 13\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_self_attn.Precision.out_proj_weight is changed to 14\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_self_attn.Precision.result is changed to 13\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_add1.Precision.result is changed to 16\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_norm2.Precision.var_table is changed to 19\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_norm2.VarTableSize is changed to 8\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_norm2.Precision.result is changed to 22\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_ffn.Precision.in_proj_weight is changed to 14\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_ffn.Precision.out_proj_weight is changed to 23\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_ffn.Precision.hidden is changed to 20\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_ffn.Precision.result is changed to 19\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_1_add2.Precision.result is changed to 19\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_2_norm1.Precision.var_table is changed to 13\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_2_norm1.VarTableSize is changed to 15\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_2_norm1.Precision.result is changed to 19\n",
      "Interpreting Model ...\n",
      "Topology:\n",
      "Layer 2: TransformerEncoder\n",
      "Layer name: transformer_encoder, layer type: LayerGroup, input shape: [[1, 180, 182]]\n",
      "Creating HLS model\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "LayerGroup initialized\n",
      "[[1, 180, 182]]\n",
      "Writing HLS project\n",
      "Done\n",
      "layers_2_norm1.Precision.result is not correct\n",
      "tensor([[[-0.026279449462891, -0.040798187255859, -0.037048339843750,\n",
      "           ..., -0.046588897705078, -0.024101257324219,\n",
      "          -0.015403747558594]],\n",
      "\n",
      "        [[-0.027095794677734, -0.040847778320312, -0.037334442138672,\n",
      "           ..., -0.046947479248047, -0.024543762207031,\n",
      "          -0.015792846679688]],\n",
      "\n",
      "        [[-0.028041839599609, -0.043907165527344, -0.037322998046875,\n",
      "           ..., -0.049549102783203, -0.022281646728516,\n",
      "          -0.015930175781250]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.037036895751953,  0.083240509033203, -0.030296325683594,\n",
      "           ...,  0.001239776611328,  0.016662597656250,\n",
      "           0.105449676513672]],\n",
      "\n",
      "        [[ 0.035144805908203,  0.081905364990234, -0.030509948730469,\n",
      "           ...,  0.001113891601562,  0.016830444335938,\n",
      "           0.107105255126953]],\n",
      "\n",
      "        [[ 0.035068511962891,  0.079605102539062, -0.030666351318359,\n",
      "           ...,  0.002258300781250,  0.022258758544922,\n",
      "           0.110202789306641]]], dtype=torch.float64)\n",
      "[-0.02625275 -0.04078674 -0.03705597 ...  0.00230026  0.0222435\n",
      "  0.11023331]\n"
     ]
    }
   ],
   "source": [
    "#test if hls_model and qmodel have the same output with random batch and random change in state\n",
    "import hls4ml\n",
    "import torch\n",
    "import numpy as np\n",
    "from quantizers import *\n",
    "from synchronizer import *\n",
    "from src.model import NeuralDataTransformer\n",
    "import json\n",
    "model_config = torch.load('./2a5324c4.lve.pth', map_location=torch.device('cpu'))\n",
    "print('model_config', model_config.keys())\n",
    "model = NeuralDataTransformer(model_config['config'][\"MODEL\"], 180, 182, torch.device('cpu'), 7)\n",
    "model.load_state_dict(model_config['state_dict'])\n",
    "\n",
    "model4hls = torch.load('./model4hls.pth')\n",
    "BRAMstate = gen_init_BRAMaware_state(4)\n",
    "DSPstate = gen_init_nonBRAMaware_state(4)\n",
    "#merge BRAMstate and DSPstate\n",
    "state = {**BRAMstate, **DSPstate}\n",
    "transformer_quant_config = torch.load('./transformer_quant_config.pth')\n",
    "config = hls4ml.utils.config_from_pytorch_model(model4hls, \n",
    "                                                granularity='name',\n",
    "                                                backend='Vitis',\n",
    "                                                input_shapes=[[1, 180, 182]], \n",
    "                                                default_precision='ap_fixed<18,7,AP_RND_CONV>', \n",
    "                                                inputs_channel_last=True, \n",
    "                                                transpose_outputs=False)\n",
    "import random\n",
    "for key in state.keys():\n",
    "    rnd_bits = random.randint(1, 5)\n",
    "    rnd_signed = random.choice([True, False])\n",
    "    rnd_batch = random.randint(1, 546)\n",
    "    state[key] = state[key] + rnd_bits if rnd_signed else state[key] - rnd_bits\n",
    "    transformer_quant_config = sync_quant_config(transformer_quant_config, config,state)\n",
    "    print(f'{key} is changed to {state[key]}')\n",
    "    hls_model = hls4ml.converters.convert_from_pytorch_model(\n",
    "                                                                model4hls,\n",
    "                                                                [[1, 180, 182]],\n",
    "                                                                output_dir='./hls/ndt_calibrate',\n",
    "                                                                project_name='myproject',\n",
    "                                                                backend='Vitis',\n",
    "                                                                #part='xcu250-figd2104-2L-e',\n",
    "                                                                part='xcu55c-fsvh2892-2L-e',\n",
    "                                                                #board='alveo-u55c',\n",
    "                                                                hls_config=config,\n",
    "                                                                io_type='io_tile_stream',\n",
    "                                                            )\n",
    "    hls_model.compile()\n",
    "    qmodel = QTransformerEncoder([QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[0], calibration=False, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[1], calibration=False, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[2], calibration=False, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[3], calibration=False, device='cpu')], \n",
    "                             4, \n",
    "                             QLayerNorm(182, quant_config=transformer_quant_config['norm'], calibration=False, device='cpu'),\n",
    "                             TorchQuantizer(bitwidth=18, int_bitwidth=7, signed=True, calibration=False),\n",
    "                             dtype=torch.float64)\n",
    "    qmodel.transfer_weights(model4hls)\n",
    "    qmodel.to(torch.device('cpu'))\n",
    "    model.eval()\n",
    "    qmodel.eval()\n",
    "    with torch.no_grad():\n",
    "        x = model.embedder(src[rnd_batch:rnd_batch+1].permute(1, 0, 2)) * model.scale\n",
    "        x = model.pos_encoder(x)\n",
    "        qy = qmodel(x.type(torch.float64).to(torch.device('cpu')), mask=model._get_or_generate_context_mask(x))\n",
    "        hls_y = hls_model.predict(x.cpu().numpy())\n",
    "        #check if qy and y are close enough\n",
    "        if torch.max(torch.abs(qy.flatten() - torch.tensor(hls_y).flatten())) > 1e-3:\n",
    "            print(f'{key} is not correct')\n",
    "            #save state and transformer_quant_config to json\n",
    "            with open('./state.json', 'w') as f:\n",
    "                json.dump(state, f)\n",
    "            with open('./transformer_quant_config.json', 'w') as f:\n",
    "                json.dump(transformer_quant_config, f)\n",
    "            with open('./config.json', 'w') as f:\n",
    "                json.dump(config, f)\n",
    "            print(qy)\n",
    "            print(hls_y)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x = model.embedder(src.permute(1, 0, 2)) * model.scale\n",
    "    x = model.pos_encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.414709568023682e-01,  5.403023362159729e-01,\n",
       "           7.856467962265015e-01,  ...,\n",
       "           1.000000000000000e+00,  1.106511626858264e-04,\n",
       "           1.000000000000000e+00]],\n",
       "\n",
       "        [[ 9.092974066734314e-01, -4.161468446254730e-01,\n",
       "           9.721205234527588e-01,  ...,\n",
       "           1.000000000000000e+00,  2.213023253716528e-04,\n",
       "           1.000000000000000e+00]],\n",
       "\n",
       "        [[ 1.411200016736984e-01, -9.899924993515015e-01,\n",
       "           4.172068834304810e-01,  ...,\n",
       "           9.999999403953552e-01,  3.319534880574793e-04,\n",
       "           9.999999403953552e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 8.775753378868103e-01, -4.794387817382812e-01,\n",
       "          -6.009308695793152e-01,  ...,\n",
       "           9.997625350952148e-01,  1.969463378190994e-02,\n",
       "           9.998060464859009e-01]],\n",
       "\n",
       "        [[ 7.072217017412186e-02, -9.974960684776306e-01,\n",
       "          -9.997491836547852e-01,  ...,\n",
       "           9.997598528862000e-01,  1.980526372790337e-02,\n",
       "           9.998038411140442e-01]],\n",
       "\n",
       "        [[-8.011526465415955e-01, -5.984600782394409e-01,\n",
       "          -6.361110806465149e-01,  ...,\n",
       "           9.997571706771851e-01,  1.991589181125164e-02,\n",
       "           9.998016357421875e-01]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(config, './debug_config.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state, './debug_state.pth')\n",
    "torch.save(transformer_quant_config, './debug_transformer_quant_config.pth')\n",
    "#load txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load txt\n",
    "query = np.loadtxt(\"ffn_hidden.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/ffn_hidden_debug.txt\")\n",
    "np.savetxt(\"ffn_hidden.txt\", query, fmt='%.6f')\n",
    "np.savetxt(\"./hls/ndt_calibrate/firmware/ffn_hidden_debug.txt\", hls_query, fmt='%.6f')\n",
    "query = np.loadtxt(\"ffn_hidden.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/ffn_hidden_debug.txt\")\n",
    "\n",
    "#plot the difference between query and hls_query with heat map using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(query[0:180]-hls_query[0:180], cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load txt\n",
    "query = np.loadtxt(\"ffn_out.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/ffn_res_debug.txt\")\n",
    "np.savetxt(\"ffn_out.txt\", query, fmt='%.6f')\n",
    "np.savetxt(\"./hls/ndt_calibrate/firmware/ffn_res_debug.txt\", hls_query, fmt='%.6f')\n",
    "query = np.loadtxt(\"ffn_out.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/ffn_res_debug.txt\")\n",
    "\n",
    "#plot the difference between query and hls_query with heat map using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(query[0:180]-hls_query[0:180], cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load txt\n",
    "query = np.loadtxt(\"norm_out.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/ln_res_debug.txt\")\n",
    "np.savetxt(\"norm_out.txt\", query, fmt='%.6f')\n",
    "np.savetxt(\"./hls/ndt_calibrate/firmware/ln_res_debug.txt\", hls_query, fmt='%.6f')\n",
    "query = np.loadtxt(\"norm_out.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/ln_res_debug.txt\")\n",
    "\n",
    "#plot the difference between query and hls_query with heat map using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(query[540:720]-hls_query[540:720], cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load txt\n",
    "query = np.loadtxt(\"norm_in.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/ln_in_debug.txt\")\n",
    "np.savetxt(\"norm_in.txt\", query, fmt='%.6f')\n",
    "np.savetxt(\"./hls/ndt_calibrate/firmware/ln_in_debug.txt\", hls_query, fmt='%.6f')\n",
    "query = np.loadtxt(\"norm_in.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/ln_in_debug.txt\")\n",
    "\n",
    "#plot the difference between query and hls_query with heat map using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(query[540:720]-hls_query[540:720], cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 182)\n",
      "(720, 182)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load txt\n",
    "query = np.loadtxt(\"q.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/Q_debug.txt\")\n",
    "np.savetxt(\"q.txt\", query, fmt='%.6f')\n",
    "np.savetxt(\"./hls/ndt_calibrate/firmware/Q_debug.txt\", hls_query, fmt='%.6f')\n",
    "query = np.loadtxt(\"q.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/Q_debug.txt\")\n",
    "print(query.shape)\n",
    "print(hls_query.shape)\n",
    "#plot the difference between query and hls_query with heat map using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(query[0:180]-hls_query[0:180], cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 182)\n",
      "(720, 182)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load txt\n",
    "query = np.loadtxt(\"k.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/K_debug.txt\")\n",
    "np.savetxt(\"k.txt\", query, fmt='%.6f')\n",
    "np.savetxt(\"./hls/ndt_calibrate/firmware/K_debug.txt\", hls_query, fmt='%.6f')\n",
    "query = np.loadtxt(\"k.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/K_debug.txt\")\n",
    "print(query.shape)\n",
    "print(hls_query.shape)\n",
    "#plot the difference between query and hls_query with heat map using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(query[0:180]-hls_query[0:180], cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 182)\n",
      "(720, 182)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load txt\n",
    "query = np.loadtxt(\"query.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/data_debug.txt\")\n",
    "np.savetxt(\"query.txt\", query, fmt='%.6f')\n",
    "np.savetxt(\"./hls/ndt_calibrate/firmware/data_debug.txt\", hls_query, fmt='%.6f')\n",
    "query = np.loadtxt(\"query.txt\")\n",
    "hls_query = np.loadtxt(\"./hls/ndt_calibrate/firmware/data_debug.txt\")\n",
    "print(query.shape)\n",
    "print(hls_query.shape)\n",
    "#plot the difference between query and hls_query with heat map using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(query[0:180]-hls_query[0:180], cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'ffn': {'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 2},\n",
      "                         'input': {'bitwidth': 18,\n",
      "                                   'int_bitwidth': -inf,\n",
      "                                   'quantize': False},\n",
      "                         'output': {'bitwidth': 18,\n",
      "                                    'int_bitwidth': -inf,\n",
      "                                    'quantize': False},\n",
      "                         'weight': {'bitwidth': 18, 'int_bitwidth': 5}},\n",
      "             'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "                          'input': {'bitwidth': 18, 'int_bitwidth': 5},\n",
      "                          'output': {'bitwidth': 18, 'int_bitwidth': 9},\n",
      "                          'weight': {'bitwidth': 18, 'int_bitwidth': 5}}},\n",
      "     'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "     'norm1': {'bias': {'bitwidth': 18, 'int_bitwidth': 1},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 6},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 1},\n",
      "               'output': {'bitwidth': 14, 'int_bitwidth': 3},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "               'var_input': {'bitwidth': 12,\n",
      "                             'int_bitwidth': 4,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 17,\n",
      "                              'int_bitwidth': 2,\n",
      "                              'signed': False}},\n",
      "     'norm2': {'bias': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "               'input': {'bitwidth': 14, 'int_bitwidth': 9},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 2},\n",
      "               'output': {'bitwidth': 14, 'int_bitwidth': 4},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "               'var_input': {'bitwidth': 9, 'int_bitwidth': 9, 'signed': False},\n",
      "               'var_output': {'bitwidth': 21,\n",
      "                              'int_bitwidth': -2,\n",
      "                              'signed': False}},\n",
      "     'self_attn': {'exp_input': {'bitwidth': 14, 'int_bitwidth': 4},\n",
      "                   'exp_output': {'bitwidth': 13,\n",
      "                                  'int_bitwidth': 8,\n",
      "                                  'signed': False},\n",
      "                   'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "                               'input': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "                               'output': {'bitwidth': 22, 'int_bitwidth': 5},\n",
      "                               'weight': {'bitwidth': 16, 'int_bitwidth': 4}},\n",
      "                   'inv_input': {'bitwidth': 12,\n",
      "                                 'int_bitwidth': 6,\n",
      "                                 'signed': False},\n",
      "                   'inv_output': {'bitwidth': 21,\n",
      "                                  'int_bitwidth': 0,\n",
      "                                  'signed': False},\n",
      "                   'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 4},\n",
      "                                'input': {'bitwidth': 20, 'int_bitwidth': 8},\n",
      "                                'output': {'bitwidth': 17, 'int_bitwidth': 9},\n",
      "                                'weight': {'bitwidth': 20, 'int_bitwidth': 4}},\n",
      "                   'row_sum': {'bitwidth': 18,\n",
      "                               'int_bitwidth': 6,\n",
      "                               'signed': False},\n",
      "                   'scale': {'bitwidth': 18, 'int_bitwidth': 0}}},\n",
      " 1: {'ffn': {'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 2},\n",
      "                         'input': {'bitwidth': 18,\n",
      "                                   'int_bitwidth': -inf,\n",
      "                                   'quantize': False},\n",
      "                         'output': {'bitwidth': 18,\n",
      "                                    'int_bitwidth': -inf,\n",
      "                                    'quantize': False},\n",
      "                         'weight': {'bitwidth': 18, 'int_bitwidth': 3}},\n",
      "             'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 4},\n",
      "                          'input': {'bitwidth': 18, 'int_bitwidth': 7},\n",
      "                          'output': {'bitwidth': 18, 'int_bitwidth': 11},\n",
      "                          'weight': {'bitwidth': 18, 'int_bitwidth': 5}}},\n",
      "     'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "     'norm1': {'bias': {'bitwidth': 18, 'int_bitwidth': -2},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 10},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 2},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 1},\n",
      "               'var_input': {'bitwidth': 10,\n",
      "                             'int_bitwidth': 11,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': -2,\n",
      "                              'signed': False}},\n",
      "     'norm2': {'bias': {'bitwidth': 18, 'int_bitwidth': 4},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 10},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 4},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "               'var_input': {'bitwidth': 10,\n",
      "                             'int_bitwidth': 13,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': -5,\n",
      "                              'signed': False}},\n",
      "     'self_attn': {'exp_input': {'bitwidth': 10, 'int_bitwidth': 4},\n",
      "                   'exp_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': 8,\n",
      "                                  'signed': False},\n",
      "                   'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "                               'input': {'bitwidth': 18, 'int_bitwidth': 2},\n",
      "                               'output': {'bitwidth': 18, 'int_bitwidth': 5},\n",
      "                               'weight': {'bitwidth': 18, 'int_bitwidth': 4}},\n",
      "                   'inv_input': {'bitwidth': 10,\n",
      "                                 'int_bitwidth': 6,\n",
      "                                 'signed': False},\n",
      "                   'inv_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': -2,\n",
      "                                  'signed': False},\n",
      "                   'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 4},\n",
      "                                'input': {'bitwidth': 18, 'int_bitwidth': 10},\n",
      "                                'output': {'bitwidth': 18, 'int_bitwidth': 10},\n",
      "                                'weight': {'bitwidth': 18, 'int_bitwidth': 4}},\n",
      "                   'row_sum': {'bitwidth': 18,\n",
      "                               'int_bitwidth': 6,\n",
      "                               'signed': False},\n",
      "                   'scale': {'bitwidth': 18, 'int_bitwidth': 0}}},\n",
      " 2: {'ffn': {'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "                         'input': {'bitwidth': 18,\n",
      "                                   'int_bitwidth': -inf,\n",
      "                                   'quantize': False},\n",
      "                         'output': {'bitwidth': 18,\n",
      "                                    'int_bitwidth': -inf,\n",
      "                                    'quantize': False},\n",
      "                         'weight': {'bitwidth': 18, 'int_bitwidth': 4}},\n",
      "             'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 5},\n",
      "                          'input': {'bitwidth': 18, 'int_bitwidth': 7},\n",
      "                          'output': {'bitwidth': 18, 'int_bitwidth': 10},\n",
      "                          'weight': {'bitwidth': 18, 'int_bitwidth': 5}}},\n",
      "     'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "     'norm1': {'bias': {'bitwidth': 18, 'int_bitwidth': -2},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 11},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 2},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 1},\n",
      "               'var_input': {'bitwidth': 10,\n",
      "                             'int_bitwidth': 14,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': -5,\n",
      "                              'signed': False}},\n",
      "     'norm2': {'bias': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 11},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 4},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 5},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "               'var_input': {'bitwidth': 10,\n",
      "                             'int_bitwidth': 16,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': -6,\n",
      "                              'signed': False}},\n",
      "     'self_attn': {'exp_input': {'bitwidth': 10, 'int_bitwidth': 4},\n",
      "                   'exp_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': 8,\n",
      "                                  'signed': False},\n",
      "                   'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "                               'input': {'bitwidth': 18, 'int_bitwidth': 2},\n",
      "                               'output': {'bitwidth': 18, 'int_bitwidth': 6},\n",
      "                               'weight': {'bitwidth': 18, 'int_bitwidth': 4}},\n",
      "                   'inv_input': {'bitwidth': 10,\n",
      "                                 'int_bitwidth': 6,\n",
      "                                 'signed': False},\n",
      "                   'inv_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': -2,\n",
      "                                  'signed': False},\n",
      "                   'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "                                'input': {'bitwidth': 18, 'int_bitwidth': 11},\n",
      "                                'output': {'bitwidth': 18, 'int_bitwidth': 10},\n",
      "                                'weight': {'bitwidth': 18, 'int_bitwidth': 4}},\n",
      "                   'row_sum': {'bitwidth': 18,\n",
      "                               'int_bitwidth': 6,\n",
      "                               'signed': False},\n",
      "                   'scale': {'bitwidth': 18, 'int_bitwidth': 0}}},\n",
      " 3: {'ffn': {'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "                         'input': {'bitwidth': 18,\n",
      "                                   'int_bitwidth': -inf,\n",
      "                                   'quantize': False},\n",
      "                         'output': {'bitwidth': 18,\n",
      "                                    'int_bitwidth': -inf,\n",
      "                                    'quantize': False},\n",
      "                         'weight': {'bitwidth': 18, 'int_bitwidth': 4}},\n",
      "             'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 4},\n",
      "                          'input': {'bitwidth': 18, 'int_bitwidth': 7},\n",
      "                          'output': {'bitwidth': 18, 'int_bitwidth': 10},\n",
      "                          'weight': {'bitwidth': 18, 'int_bitwidth': 5}}},\n",
      "     'input': {'bitwidth': 18, 'int_bitwidth': 8},\n",
      "     'norm1': {'bias': {'bitwidth': 18, 'int_bitwidth': -1},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 12},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 4},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 2},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 1},\n",
      "               'var_input': {'bitwidth': 10,\n",
      "                             'int_bitwidth': 16,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': -6,\n",
      "                              'signed': False}},\n",
      "     'norm2': {'bias': {'bitwidth': 18, 'int_bitwidth': 4},\n",
      "               'input': {'bitwidth': 18, 'int_bitwidth': 12},\n",
      "               'mean': {'bitwidth': 18, 'int_bitwidth': 5},\n",
      "               'output': {'bitwidth': 18, 'int_bitwidth': 4},\n",
      "               'scale': {'bitwidth': 18, 'int_bitwidth': 2},\n",
      "               'var_input': {'bitwidth': 10,\n",
      "                             'int_bitwidth': 17,\n",
      "                             'signed': False},\n",
      "               'var_output': {'bitwidth': 18,\n",
      "                              'int_bitwidth': -7,\n",
      "                              'signed': False}},\n",
      "     'self_attn': {'exp_input': {'bitwidth': 10, 'int_bitwidth': 4},\n",
      "                   'exp_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': 8,\n",
      "                                  'signed': False},\n",
      "                   'in_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 3},\n",
      "                               'input': {'bitwidth': 18, 'int_bitwidth': 2},\n",
      "                               'output': {'bitwidth': 18, 'int_bitwidth': 6},\n",
      "                               'weight': {'bitwidth': 18, 'int_bitwidth': 4}},\n",
      "                   'inv_input': {'bitwidth': 10,\n",
      "                                 'int_bitwidth': 6,\n",
      "                                 'signed': False},\n",
      "                   'inv_output': {'bitwidth': 18,\n",
      "                                  'int_bitwidth': -2,\n",
      "                                  'signed': False},\n",
      "                   'out_proj': {'bias': {'bitwidth': 18, 'int_bitwidth': 4},\n",
      "                                'input': {'bitwidth': 18, 'int_bitwidth': 11},\n",
      "                                'output': {'bitwidth': 18, 'int_bitwidth': 11},\n",
      "                                'weight': {'bitwidth': 18, 'int_bitwidth': 5}},\n",
      "                   'row_sum': {'bitwidth': 18,\n",
      "                               'int_bitwidth': 7,\n",
      "                               'signed': False},\n",
      "                   'scale': {'bitwidth': 18, 'int_bitwidth': 0}}},\n",
      " 'norm': {'bias': {'bitwidth': 18, 'int_bitwidth': -3},\n",
      "          'input': {'bitwidth': 18, 'int_bitwidth': 12},\n",
      "          'mean': {'bitwidth': 18, 'int_bitwidth': 5},\n",
      "          'output': {'bitwidth': 18, 'int_bitwidth': 0},\n",
      "          'scale': {'bitwidth': 18, 'int_bitwidth': -2},\n",
      "          'var_input': {'bitwidth': 10, 'int_bitwidth': 18, 'signed': False},\n",
      "          'var_output': {'bitwidth': 18, 'int_bitwidth': -8, 'signed': False}}}\n"
     ]
    }
   ],
   "source": [
    "pprint(transformer_quant_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel = QTransformerEncoder([QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[0], calibration=False, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[1], calibration=False, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[2], calibration=False, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[3], calibration=False, device='cpu')], \n",
    "                             4, \n",
    "                             QLayerNorm(182, quant_config=transformer_quant_config['norm'], calibration=False, device='cpu'),\n",
    "                             TorchQuantizer(bitwidth=18, int_bitwidth=6, signed=True, calibration=False, rounding='TRUNCATE', saturation='SAT'),\n",
    "                             dtype=torch.float64)\n",
    "qmodel.transfer_weights(model)\n",
    "qmodel.to(torch.device('cpu'))\n",
    "batch = 10\n",
    "model.to(torch.device('cpu'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x = model.embedder(src[0:batch].permute(1, 0, 2)) * model.scale\n",
    "    x = model.pos_encoder(x)\n",
    "    qmodel.eval()\n",
    "    qy = qmodel(x.type(torch.float64).to(torch.device('cpu')), mask=model._get_or_generate_context_mask(x))\n",
    "    #print(qy)\n",
    "    print(x.shape)\n",
    "    y = model.transformer_encoder(x, mask=model._get_or_generate_context_mask(x))\n",
    "    #print(y)\n",
    "    pred_rates = model.decoder(qy.type(torch.float32)).permute(1, 0, 2) # t x b x n\n",
    "    loss = model.classifier(pred_rates, mask_labels[0:batch])\n",
    "    torch_masked_loss = loss[mask_labels[0:batch] != -100]\n",
    "    torch_masked_loss = torch_masked_loss.mean()\n",
    "    print(torch_masked_loss)\n",
    "    print(bits_per_spike(pred_rates[:,:140,137:182].cpu().numpy(), spikes_heldout[0:batch,:,:].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test time in cpu\n",
    "qmodel = QTransformerEncoder([QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[0], calibration=False, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[1], calibration=False, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[2], calibration=False, device='cpu'),\n",
    "                              QTransformerEncoderLayer(182, 2, 128, quant_config=transformer_quant_config[3], calibration=False, device='cpu')], \n",
    "                             4, \n",
    "                             QLayerNorm(182, quant_config=transformer_quant_config['norm'], calibration=False, device='cpu'),\n",
    "                             TorchQuantizer(bitwidth=18, int_bitwidth=6, signed=True, calibration=False, rounding='TRUNCATE', saturation='SAT'),\n",
    "                             dtype=torch.float64)\n",
    "qmodel.transfer_weights(model)\n",
    "qmodel.to(torch.device('cpu'))\n",
    "batch = 547\n",
    "model.to(torch.device('cpu'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x = model.embedder(src[0:batch].permute(1, 0, 2).to(torch.device('cpu'))) * model.scale\n",
    "    x = model.pos_encoder(x)\n",
    "    qmodel.eval()\n",
    "    qy = qmodel(x.type(torch.float64).to(torch.device('cpu')), mask=model._get_or_generate_context_mask(x))\n",
    "    print(qy)\n",
    "    print(x.shape)\n",
    "    y = model.transformer_encoder(x, mask=model._get_or_generate_context_mask(x))\n",
    "    print(y)\n",
    "    pred_rates = model.decoder(qy.type(torch.float32)).permute(1, 0, 2) # t x b x n\n",
    "    loss = model.classifier(pred_rates, mask_labels[0:batch])\n",
    "    torch_masked_loss = loss[mask_labels[0:batch] != -100]\n",
    "    torch_masked_loss = torch_masked_loss.mean()\n",
    "    print(torch_masked_loss)\n",
    "    print(bits_per_spike(pred_rates[:,:140,137:182].cpu().numpy(), spikes_heldout[0:batch,:,:].cpu().numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto-hls4ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
